
var clone = require('clone.js');
var zlib = require('zlib')
var utils = require('utils')

//copied from packFile:
var types = { 
	0 : 'invalid',
	1 : 'commit',
	2 : 'tree',
	3 : 'blob',
	4 : 'tag',
	5 : 'invalid',
	6 : 'delta1', // DELTA_ENCODED object w/ offset to base
	7 : 'delta2'  // DELTA_ENCODED object w/ base BINARY_OBJ_ID
}

//  Decodes encoded length. If the most sign. bit is set - read next byte
// @param buffer - delta encoded objects
// @param objectOffset - index of object's first byte in pack file
// returns pair: number of bytes read, length
function getIntLE128Base(buffer, bufferIndex)
{
	var moreFlag = 1;
	var length = 0;
	var coeff = 1;
	while (moreFlag !== 0)
	{
		var nextByte = buffer[bufferIndex];
		bufferIndex += 1;
		moreFlag = nextByte & 128;
		var lengthBits = nextByte & (~128);
		length += lengthBits * coeff;
		coeff *= 64;// *2^6
	}
	return [bufferIndex, length];
}

/**
 * based on packFile:
 * Read object data header from begining of the buffer
 * @param buffer 
 * @return array [type of object, where the object starts, inflated length of data]
 */
var getLenType = function(buffer)
{
    var index = 0;
    var firstByte = buffer[index];
    index += 1;

    var length = firstByte & (1 + 2 + 4 + 8);//bits 0-3
    var typeCode = (firstByte & (16 + 32 + 64)) / 16;//bits 6-4
    var type = types[typeCode];
    var moreFlag = (firstByte & 128)/128;
    var coeff = 16;
    while (moreFlag !== 0)
    {
            var nextByte = buffer[index];
            index += 1;
            moreFlag = nextByte & 128;
            var lengthBits = nextByte & (~128);
            length += lengthBits * coeff;
            coeff *= 64;// *2^6
    }
    return [type, index, length];
}

/**
 * check if buffer contains good pack 
 * TODO check sha1 at the end and rename it to checkPack 
 */
var checkSignature = function(data)
{
    var toComp = new Buffer("PACK");
    for(var i = 0; i < toComp.length; i++)
    {
        if(data[i] != toComp[i])
            return false
    }
    return true;
}
/**
 * helper for reading version and numbers of objects in pack
 */
var read4ByteNetwOrd = function(buf)
{
    var res = 0;
    for(var i = 0; i < 4; i++)
    {
        res *= 256; //16^2
        res += buf[i];
    }
    return res;
}
/**
 * check if whole pref is prefix of buffer
 */
var prefix = function(pref, buf)
{
    if(pref.length > buf.length)
        return false;
    for(var i = 0; i < pref.length; i++)
    {
        if(pref[i] != buf[i])
            return false;
    }
    return true;
}

/**
 * Class for holding data of object data in packfile 
 */
objectInPack = function(object_data, data_type, header_offset, data_offset, packedLen, unpackedLen)
{
    this.object_data = object_data;
    this.data_type = data_type;
    this.header_offset = header_offset;
    this.data_offset = data_offset;
    this.packedLen = packedLen;
    this.unpackedLen = unpackedLen;
}

//prevs[object_data, type, counter_offset, object_offset, packedLen, unpackedLen]
/**
 * seeks through packfile and gather data about object_data, if something fails
 * calls wrongCompression to change to lvl+1 or produce error 
 * @param objData (buffer) packfile without hedar, intact through seek
 * @param cutData buffer with data to be parsed
 * @param elems how many elements are in packfile
 * @param parsed how many elements were parsed
 * @param prevs array[objectInPack] - information about parsed object data
 * @param callback([objectInPack], levelOfCompression)
 */
var seek = function(objData, cutData, elems, parsed, lvl, prevs, callback)
{
    console.log("Seek called with: elems: "+ elems+" parsed: "+parsed+ " lvl: "+lvl);
    if(parsed == elems)
    {
        if(cutData.length == 20)
        {
            callback(prevs, lvl);
            return;
        }
        else
        {
            console.log('Lost some info');
            wrongCompression(objData, elems, lvl, callback)();
        }
    }
    var len = getLenType(cutData, 0);
    console.log(len);
    var inflatedLength = len[2];
    var cut = len[1];
    var type = len[0];
    var ans = [];
    var inflate = zlib.createInflate();
    //
    if(type === 'delta1')
    {
        var len2 = getIntLE128Base(cutData, cut);
        cut += len2[0];
        inflatedLength = len2[1]; //????
    }
    else if(type === 'delta2')
    {
        cut += 20; //20 byte base name 
        
    }
    cutData = cutData.slice(cut, cutData.length);
    inflate.on('end', function(){
        var last = Buffer.concat(ans);
        console.log(last.length);
        console.log(last.toString());
        if(last.length != inflatedLength || type === 'delta2') // do not check for deltas?
        {
            wrongCompression(objData, elems, lvl, callback)();
            console.log(last.toString());
            console.log('Wrong inflation ' + last.length + " != " + inflatedLength);
            //throw 'Wrong inflation ' + last.length + " != " + inflatedLength;
        }
        utils.deflateOpts(last, function(err, deflatedData){
            if(err)
                throw err;
            else
            {
                if((!prefix(deflatedData, cutData)) || elems < parsed)
                {
                    console.log('Prefix doesent match');
                    wrongCompression(objData, elems, lvl, callback)(); //YUP, calling closure;
                }
                else
                {
                    prevs.push(new objectInPack(last, type, objData.length - cutData.length, 
                        objData.length - cutData.length + cut, deflatedData.length, inflatedLength));
                    console.log("CUTTING " + deflatedData.length+ "   " + cutData.length);
                    seek(objData, cutData.slice(deflatedData.length, cutData.length),
                    elems, parsed+1, lvl, prevs, callback);
                }
            }
        }, {level : lvl} );
    });
    inflate.on('data', function(data){
        console.log("DATA length: " +data.length+ " for elem: "+(parsed+1));
        ans.push(data);
    });
    inflate.on('error', wrongCompression(objData, elems, lvl, callback));
    inflate.on('drain', function(){
        console.log('drain');
    });
    inflate.on('finish', function(){
        console.log('finish');
    });
    inflate.write(cutData);
    var i = -1;
    for(var j = 0; j < 100000000; j++) 
        i++;
    inflate.end();
}

/**
 * called when seek through pack fails, iterates to next level of compression
 * (closure)
 */
var wrongCompression = function(objData, elems, level, callback)
{
    var l = level;
    var o = objData;
    var e = elems;
    return function()
    {
        if(l == 9)
            throw 'pack decompression failed';
        else
        {
            console.log('Decompression error');
            seek(o, o, e, 0, l+1, [], callback);
        }
    }
    
}

/**
 * start seekeing through packfile with -1 level of compression
 */
var callSeek = function(objData, elems, callback)
{
    seek(objData, objData, elems, 0, -1, [], callback);
}

/**
 * Parses one packfile, produces levelOf compression
 * TODO, optional argument with level of compression
 * @param pack buufer with pack
 * @param callback([objectInPack], levelOfCompression)
 */
var scanPack = function(pack, callback)
{
    //check for signature
    if(!checkSignature(pack))
        throw 'this is not a valid packfile';
    var version = read4ByteNetwOrd(pack.slice(4, 8));
    var elems = read4ByteNetwOrd(pack.slice(8, 12));
    var objData = pack.slice(12, pack.length);
    callSeek(objData, elems, function(data, lvl){
        console.log(data.length);
        console.log("Used compression level is: ", lvl);
        callback(data, lvl);
        
    });
}

/**
 * Rebuilds objects from packfile
 * @param pack buffer with pack 
 * @param scan [objectInPack] - information about parsed object data
 */
var rebuildObjects = function(pack, scan)
{
    var fullObjects = [];
    var existingObjects = [];
    var deltas = [];
    scan.forEach(function(element){
        if(element.data_type === 'delta1' || element.data_type === 'delta2')
            deltas.push(element);
        else
            existingObjects.push(element);
    });
    existingObjects.forEach(function(elem){
        var header = elem.data_type + " " + elem.unpackedLen +'\0';
        var head = new Buffer(header);
        var object = Buffer.concat([head, elem.object_data]);
        var sha1 = utils.getSha1(object);
       fullObjects[sha1] = object;
    });
    //console.log(fullObjects);
    return fullObjects;
}

/**
 * Saves rebuild objects in repo
 * @param objects objects from rebuildObjects
 * @param repoPath string with path to repo
 */
var saveInRepo = function(objects, repoPath)
{
    
    for(var propt in objects){
        utils.saveObject(objects[propt], repoPath); 
    }
}
/**
 * This does the whole clone
 * TODO one procedure for clone
 */
var test = function(packs)
{
    var fs = require('fs');
    var pck = fs.readFileSync("pack.pack");
    console.log(prefix(pck, packs[0]));
    console.log(prefix(packs[0], pck));
    scanPack(packs[0], function(data, lvl){
        
        var objects = rebuildObjects(packs[0], data);
        console.log(objects);
        saveInRepo(objects, "test");
    });
}
//clone.getPacks('git://github.com/kyloel/clone.git', test);


exports.scanPack = scanPack;
exports.rebuildObjects = rebuildObjects;
exports.saveInRepo = saveInRepo;